{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-17T15:35:31.200419Z",
     "start_time": "2024-04-17T15:21:53.401805Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:counterfactual_xai.utils.lsat_dataloader.lsat_dataloader:Formatting Dataframes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 0.04M\n",
      "Init cost variables:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukasscholz/repositorys/counterfactuals/counterfactual_xai/utils/clue/bnn/stochastic_gradient_hamilton_sampler.py:80: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/python_arg_parser.cpp:1630.)\n",
      "  d_p.add_(weight_decay, p.data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it 0/2200, Jtr_pred = 1.409488, it 1/2200, Jtr_pred = 1.351609, it 2/2200, Jtr_pred = 1.348958, it 3/2200, Jtr_pred = 1.348597, it 4/2200, Jtr_pred = 1.347855, it 5/2200, Jtr_pred = 1.343386, it 6/2200, Jtr_pred = 1.345929, it 7/2200, Jtr_pred = 1.354947, it 8/2200, Jtr_pred = 1.344402, it 9/2200, Jtr_pred = 1.344058, it 10/2200, Jtr_pred = 1.343259, it 11/2200, Jtr_pred = 1.348125, it 12/2200, Jtr_pred = 1.346650, it 13/2200, Jtr_pred = 1.349946, it 14/2200, Jtr_pred = 1.345492, it 15/2200, Jtr_pred = 1.347671, it 16/2200, Jtr_pred = 1.345094, it 17/2200, Jtr_pred = 1.343143, it 18/2200, Jtr_pred = 1.349923, it 19/2200, Jtr_pred = 1.346336, it 20/2200, Jtr_pred = 1.342309, it 21/2200, Jtr_pred = 1.348282, it 22/2200, Jtr_pred = 1.342767, it 23/2200, Jtr_pred = 1.345634, it 24/2200, Jtr_pred = 1.343228, it 25/2200, Jtr_pred = 1.346224, it 26/2200, Jtr_pred = 1.344229, it 27/2200, Jtr_pred = 1.347687, it 28/2200, Jtr_pred = 1.343659, it 29/2200, Jtr_pred = 1.350407, it 30/2200, Jtr_pred = 1.343501, it 31/2200, Jtr_pred = 1.353321, it 32/2200, Jtr_pred = 1.343273, it 33/2200, Jtr_pred = 1.345885, it 34/2200, Jtr_pred = 1.341403, it 35/2200, Jtr_pred = 1.343159, it 36/2200, Jtr_pred = 1.341770, it 37/2200, Jtr_pred = 1.344002, "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 51\u001B[0m\n\u001B[1;32m     47\u001B[0m net \u001B[38;5;241m=\u001B[39m GaussianBNN(model, N_train, lr\u001B[38;5;241m=\u001B[39mlr, cuda\u001B[38;5;241m=\u001B[39mcuda)\n\u001B[1;32m     49\u001B[0m save_dir \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/Users/lukasscholz/repositorys/counterfactuals/results/\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m---> 51\u001B[0m cost_train, cost_dev, rms_dev, ll_dev \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_BNN_regression\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnet\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msave_dir\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnb_epochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrainset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcuda\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     52\u001B[0m \u001B[43m                                 \u001B[49m\u001B[43mburn_in\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msim_steps\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mN_saves\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mresample_its\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mresample_prior_its\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     53\u001B[0m \u001B[43m                                 \u001B[49m\u001B[43mre_burn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mflat_ims\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnb_its_dev\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_mu\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my_means\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_std\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my_stds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/repositorys/counterfactuals/counterfactual_xai/utils/clue/bnn/train.py:44\u001B[0m, in \u001B[0;36mtrain_BNN_regression\u001B[0;34m(model, model_name, batch_size, epochs, trainset, valset, cuda, burn_in, sim_steps, N_saves, resample_its, resample_prior_its, re_burn, flat_ims, nb_its_dev, y_mu, y_std)\u001B[0m\n\u001B[1;32m     41\u001B[0m model\u001B[38;5;241m.\u001B[39mset_model_mode(\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m     42\u001B[0m num_samples \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m---> 44\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m x, y \u001B[38;5;129;01min\u001B[39;00m trainloader:\n\u001B[1;32m     45\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m flat_ims:\n\u001B[1;32m     46\u001B[0m         x \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39mview(x\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m], \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[0;32m~/repositorys/counterfactuals/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:631\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    628\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    629\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[1;32m    630\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[0;32m--> 631\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    632\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    633\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    634\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    635\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[0;32m~/repositorys/counterfactuals/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1318\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1315\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1316\u001B[0m     \u001B[38;5;66;03m# no valid `self._rcvd_idx` is found (i.e., didn't break)\u001B[39;00m\n\u001B[1;32m   1317\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_persistent_workers:\n\u001B[0;32m-> 1318\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_shutdown_workers\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1319\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m\n\u001B[1;32m   1321\u001B[0m \u001B[38;5;66;03m# Now `self._rcvd_idx` is the batch index we want to fetch\u001B[39;00m\n\u001B[1;32m   1322\u001B[0m \n\u001B[1;32m   1323\u001B[0m \u001B[38;5;66;03m# Check if the next sample has already been generated\u001B[39;00m\n",
      "File \u001B[0;32m~/repositorys/counterfactuals/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1443\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._shutdown_workers\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1438\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_mark_worker_as_unavailable(worker_id, shutdown\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m   1439\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m w \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_workers:\n\u001B[1;32m   1440\u001B[0m     \u001B[38;5;66;03m# We should be able to join here, but in case anything went\u001B[39;00m\n\u001B[1;32m   1441\u001B[0m     \u001B[38;5;66;03m# wrong, we set a timeout and if the workers fail to join,\u001B[39;00m\n\u001B[1;32m   1442\u001B[0m     \u001B[38;5;66;03m# they are killed in the `finally` block.\u001B[39;00m\n\u001B[0;32m-> 1443\u001B[0m     \u001B[43mw\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_utils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mMP_STATUS_CHECK_INTERVAL\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1444\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m q \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_index_queues:\n\u001B[1;32m   1445\u001B[0m     q\u001B[38;5;241m.\u001B[39mcancel_join_thread()\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.7/lib/python3.10/multiprocessing/process.py:149\u001B[0m, in \u001B[0;36mBaseProcess.join\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    147\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_parent_pid \u001B[38;5;241m==\u001B[39m os\u001B[38;5;241m.\u001B[39mgetpid(), \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcan only join a child process\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    148\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_popen \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcan only join a started process\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m--> 149\u001B[0m res \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_popen\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    150\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m res \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    151\u001B[0m     _children\u001B[38;5;241m.\u001B[39mdiscard(\u001B[38;5;28mself\u001B[39m)\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.7/lib/python3.10/multiprocessing/popen_fork.py:40\u001B[0m, in \u001B[0;36mPopen.wait\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m     38\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     39\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmultiprocessing\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mconnection\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m wait\n\u001B[0;32m---> 40\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msentinel\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[1;32m     41\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     42\u001B[0m \u001B[38;5;66;03m# This shouldn't block if wait() returned successfully.\u001B[39;00m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.7/lib/python3.10/multiprocessing/connection.py:936\u001B[0m, in \u001B[0;36mwait\u001B[0;34m(object_list, timeout)\u001B[0m\n\u001B[1;32m    933\u001B[0m     deadline \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mmonotonic() \u001B[38;5;241m+\u001B[39m timeout\n\u001B[1;32m    935\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m--> 936\u001B[0m     ready \u001B[38;5;241m=\u001B[39m \u001B[43mselector\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mselect\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    937\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ready:\n\u001B[1;32m    938\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m [key\u001B[38;5;241m.\u001B[39mfileobj \u001B[38;5;28;01mfor\u001B[39;00m (key, events) \u001B[38;5;129;01min\u001B[39;00m ready]\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.7/lib/python3.10/selectors.py:416\u001B[0m, in \u001B[0;36m_PollLikeSelector.select\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    414\u001B[0m ready \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m    415\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 416\u001B[0m     fd_event_list \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_selector\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpoll\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    417\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mInterruptedError\u001B[39;00m:\n\u001B[1;32m    418\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m ready\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import division\n",
    "import torch\n",
    "\n",
    "from counterfactual_xai.utils.lsat_dataloader.lsat_dataloader import LsatDataloader\n",
    "from counterfactual_xai.utils.datafeed import DataFeed\n",
    "from counterfactual_xai.utils.clue.gaussian_mlp import GaussianMLP\n",
    "from counterfactual_xai.utils.clue.bnn.gaussian_bnn import GaussianBNN\n",
    "from counterfactual_xai.utils.clue.bnn.train import train_BNN_regression\n",
    "\n",
    "CSV_PATH = \"\"\n",
    "INPUT_DIMS = [1, 1, 8, 2]\n",
    "\n",
    "x_train, x_test, x_means, x_stds, y_train, y_test, y_means, y_stds, DATA_KEYS, input_dims = LsatDataloader(INPUT_DIMS,\n",
    "                                                                                                           CSV_PATH).get_lsat_dataset()\n",
    "\n",
    "trainset = DataFeed(x_train, y_train, transform=None)\n",
    "valset = DataFeed(x_test, y_test, transform=None)\n",
    "\n",
    "y_means = torch.Tensor(y_means)\n",
    "y_stds = torch.Tensor(y_stds)\n",
    "\n",
    "input_dim = x_train.shape[1]\n",
    "width = 200\n",
    "depth = 2\n",
    "output_dim = y_train.shape[1]\n",
    "model = GaussianMLP(input_dim, width, depth, output_dim, flatten_image=False)\n",
    "\n",
    "N_train = x_train.shape[0]\n",
    "batch_size = 512\n",
    "# nb_epochs = 2200 # We can do less iterations as this method has faster convergence\n",
    "nb_epochs = 2200\n",
    "log_interval = 1\n",
    "\n",
    "lr = 1e-2\n",
    "\n",
    "## weight saving parameters #######\n",
    "burn_in = 120  # this is in epochs \n",
    "sim_steps = 20  # We want less correlated samples -> despite having per minibatch noise we see correlations\n",
    "N_saves = 100\n",
    "\n",
    "resample_its = 10\n",
    "resample_prior_its = 50  # 45 can be choosen to better control overfitting \n",
    "re_burn = 1e7\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "net = GaussianBNN(model, N_train, lr=lr, cuda=cuda)\n",
    "\n",
    "save_dir = \"./results/\"\n",
    "\n",
    "cost_train, cost_dev, rms_dev, ll_dev = train_BNN_regression(net, save_dir, batch_size, nb_epochs, trainset, valset,\n",
    "                                                             cuda,\n",
    "                                                             burn_in, sim_steps, N_saves, resample_its,\n",
    "                                                             resample_prior_its,\n",
    "                                                             re_burn, flat_ims=False, nb_its_dev=10, y_mu=y_means,\n",
    "                                                             y_std=y_stds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "2b3fd9b8884da659"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "790ca344fc95c8da"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "9c8bdfb7d050f9f0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
